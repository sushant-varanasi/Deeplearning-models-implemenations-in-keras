{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Activation, Concatenate, BatchNormalization\n",
    "from keras.layers import Conv2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet(input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None, dropout_rate=None,\n",
    "             bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
    "    \n",
    "    if dense_layers == -1:\n",
    "        if bottleneck:\n",
    "            dense_layers = (depth - (dense_blocks + 1))/dense_blocks // 2\n",
    "        else:\n",
    "            dense_layers = (depth - (dense_blocks + 1))//dense_blocks\n",
    "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
    "    else:\n",
    "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
    "        \n",
    "    img_input = Input(shape=input_shape)\n",
    "    nb_channels = growth_rate * 2\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = Conv2D(nb_channels, (3,3), padding='same',strides=(1,1),\n",
    "                      use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
    "    \n",
    "    # Building dense blocks\n",
    "    for block in range(dense_blocks):\n",
    "        \n",
    "        # Add dense block\n",
    "        x, nb_channels = dense_block(x, dense_layers[block], nb_channels, growth_rate, dropout_rate, bottleneck, weight_decay)\n",
    "        \n",
    "        if block < dense_blocks - 1:  # if it's not the last dense block\n",
    "            # Add transition_block\n",
    "            x = transition_layer(x, nb_channels, dropout_rate, compression, weight_decay)\n",
    "            nb_channels = int(nb_channels * compression)\n",
    "    \n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(nb_classes, activation='softmax', kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "        \n",
    "    return Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
    " \n",
    "    x_list = [x]\n",
    "    for i in range(nb_layers):\n",
    "        cb = convolution_block(x, growth_rate, dropout_rate, bottleneck, weight_decay)\n",
    "        x_list.append(cb)\n",
    "        x = Concatenate(axis=-1)(x_list)\n",
    "        nb_channels += growth_rate\n",
    "    return x, nb_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
    "    \n",
    "    # Bottleneck\n",
    "    if bottleneck:\n",
    "        bottleneckWidth = 4\n",
    "        x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(nb_channels * bottleneckWidth, (1, 1), use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "        # Dropout\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Standard (BN-ReLU-Conv)\n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_channels, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "    # Dropout\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_layer(x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n",
    "    \n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nb_channels*compression), (1, 1), padding='same',\n",
    "                      use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "    # Adding dropout\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
